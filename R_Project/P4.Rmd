---
title: "Group 4 - Parkinson's P4"
author: "Meena Mishra, Raphael Kirchgaessner, Brian Karlberg"
output: html_document
---

<span style=“color:green”>
</span>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

<span><font color="ff1493">

# Load Libraries

</span>
```{r}
library(haven)
library(dplyr)
library(tidyr)
library(ggplot2)
library(moderndive)
library(infer)
library(phia)
library(tidyverse)
```
 
<span><font color="ff1493">

# Load data

</span>

```{r}
allPatients = file.path("../","All_Data_Patientstudy.sav")
allDataPatientStudyDS = read_sav(allPatients)
tidied_dataset = read.csv("tidied-dataset.csv")
```

<span><font color="ff1493">

# EDA

</span>


```{r}
glimpse(tidied_dataset)
```

```{r}
glimpse(allDataPatientStudyDS)
```
```{r include=FALSE}
variable.names(allDataPatientStudyDS)
```

<span><font color="ff1493"> 

## Relabeled columns

</span>

```{r}
allDataPatientStudyDS %>%
mutate(Sex = factor(Sex, labels = c("Female", "Male")),Group = factor(Group, labels = c("PD", "Control")))
```
```{r}
tidied_dataset <- tidied_dataset %>%
mutate(Sex = factor(Sex, labels = c("Male", "Female")),Group = factor(Group, labels = c("Control", "PD")))
```

<span><font color="ff1493">
# Replication section
</span>

<span><font color="ff1493"> 
## Table 1 Mean (SD) age, length of Parkinson, medication usage and score on the Hoehn Yahr scale
We were able to create table 1 as it appears in the paper, getting all the same values for means, range and standard deviation of age, medication, length of medication and parkinson stage (H-Y)
</span>

```{r}
#Table 1 recreated using allDataPatientStudyDS dataframe
Table1 <- tidied_dataset %>%
  filter(Group == "PD")%>%
select("Group","Age", "Medication", "Length_Parkinson","H_Y")
Table1
skimr::skim(Table1)
```

<span><font color="ff1493"> 
## Table 3 Control variable measures
Summary statistics for all control variables were replicated and they matched th evalues in the paper.
</span>

```{r}
#Table 3 using tidied_dataset
Table3 <- tidied_dataset %>%
  select("Age", "Sex", "Handedness","MMSE","RAVEN","Group")%>%
  group_by(Group)%>%
  summarize(mean_age = mean(Age), mean_handedness = mean(Handedness),mean_MMSE = mean(MMSE), mean_Raven = mean(RAVEN), count = n())
Table3_count_gender <- tidied_dataset %>%
  select("Sex","Group")%>%
  group_by(Group,Sex)%>%
  summarize(count=n())
t(Table3)
Table3_count_gender
```
<span><font color="ff1493"> 
## Table 4 Mean (SD) performance of PD and control group on the speech production tasks.
We were able to replicate table 4 as it appears in the paper. Just to point out that COWAT is a combined term for phonologic fluency and semantic fluency. So we have replicated the numbers for COWAT without calling it out. 
</span>

```{r}
#Table 4 using tidied dataset
Table4 <- tidied_dataset %>%
  group_by(Group)%>%
select("Phonologic_Fluency","Semantic_Fluency","BNT", "SyllSec_Norm", "SyllSec_Ruis", "NPro_Dur_Norm","NPro_Dur_Ruis")%>%
  summarise(mean_Phonologic_Fluency = mean(Phonologic_Fluency), sd_phonologic_fluency = sd(Phonologic_Fluency),
            mean_Semantic_Fluency = mean(Semantic_Fluency), sd_Semantic_Fluency = sd(Semantic_Fluency),
            mean_BNT = mean(BNT), sd_BNT = sd(BNT),
            mean_Syllsec_Norm = mean(SyllSec_Norm), sd_Syllsec_Norm = sd(SyllSec_Norm),
            mean_Syllsec_Ruis = mean(SyllSec_Ruis), sd_SyllSec_Ruis = sd(SyllSec_Ruis),
            mean_NPro_Dur_Norm = mean(NPro_Dur_Norm), sd_NPro_Dur_Norm = sd(NPro_Dur_Norm),
            mean_NPro_Dur_Ruis = mean(NPro_Dur_Ruis), sd_NPro_Dur_Ruis = sd(NPro_Dur_Ruis))
Table4
t(Table4)
```
<span><font color="ff1493"> 
## Table 9 Total number of disfluencies per error type in the network descriptions.

Table 9 was replicated without issues.
</span>

```{r}
#Table 9 using using tidied dataset
Table9_raw <- tidied_dataset %>%
  select("Group","Nrm_Reformulation","Nrm_FilledPause","Nrm_Repetition","Nois_Reformulation","Nois_FilledPause", "Nois_Repetition")
Table9 <- Table9_raw %>%
  gather (key = "Error_type", value = "Total_Number",-Group,"Nrm_Reformulation","Nrm_FilledPause","Nrm_Repetition","Nois_Reformulation","Nois_FilledPause", "Nois_Repetition")
Table9
aggregate(Total_Number~Error_type+Group,Table9,sum)
 
```

<span><font color="ff1493"> 
## Figure 1 and Figure 2
Replicating figure 1 and Fig 2 was hard. We found that the values for "percentage of semantic error repaired", provided in the raw dataset were not actually percentages. Closer analysis revealed that the values for "percentage semantic error repaired " may have been fractions. We recalculated percentage of semantic error repaired and used those values to come up with fig 1 and fig2. 
</span>

```{r }
#Replicating figure 1 using r=the values from raw dataset
Fig1_raw <- allDataPatientStudyDS %>%
  select("Group","Pct_NormRep","Pct_NoiseRep","PctSemNoiseRep","PctSemNormRep")%>%
  filter(Group == 0,complete.cases(Pct_NormRep,Pct_NoiseRep,PctSemNoiseRep,PctSemNormRep))%>%
  summarise(mean_Pct_NormRep=mean(Pct_NormRep),mean_Pct_NoiseRep=mean(Pct_NoiseRep),mean_PctSemNoiseRep=mean(PctSemNoiseRep),mean_PctSemNormRep=mean(PctSemNormRep, count=n()))
 
Fig1_table <- Fig1_raw %>%
  gather (key = "Error", value = "Percentage_Repaired","mean_PctSemNormRep","mean_PctSemNoiseRep","mean_Pct_NormRep","mean_Pct_NoiseRep")
ggplot(data = Fig1_table) +
  geom_col(mapping = aes(x = Error,y=Percentage_Repaired), binwidth = 0.5)
 
  
```


```{r}
#Replicating figure 2 using r=the values from raw dataset
Fig2_raw <- allDataPatientStudyDS %>%
  select("Group","Pct_NormRep","Pct_NoiseRep","PctSemNoiseRep","PctSemNormRep")%>%
  filter(complete.cases(Pct_NormRep,Pct_NoiseRep,PctSemNoiseRep,PctSemNormRep))%>%
  group_by(Group)%>%
  summarise(mean_Pct_NormRep=mean(Pct_NormRep),mean_Pct_NoiseRep=mean(Pct_NoiseRep),mean_PctSemNoiseRep=mean(PctSemNoiseRep),mean_PctSemNormRep=mean(PctSemNormRep, count=n()))
 
Fig2_table <- Fig2_raw %>%
  gather (key = "Error", value = "Percentage_Repaired","mean_PctSemNormRep","mean_PctSemNoiseRep","mean_Pct_NormRep","mean_Pct_NoiseRep")
Fig2_table %>%
  ggplot() +
  geom_col(mapping = aes(x = Error,y=Percentage_Repaired), binwidth = 0.5)+
  facet_wrap(~Group)
  
```


<span><font color="ff1493">
### Recalculating the values for percentage of semantic error and using that for replicating fig 1 and fig 2. The figues still do not resemble with what is in the paper. 
</span>

```{r}
Fig_table <- allDataPatientStudyDS %>%
  group_by(Group)%>%
  select("SemErrors_Norm","Nrm_Sem_Rep", "SemErrors_Noise","Nois_Sem_Rep", "Norm_ErrorsRepaired","Noise_ErrorsRepaired","TotalErrorsNorm_N","TotalErrorsNois_N" )%>%
  mutate(Nrm_Perc_Sem_Error_Repaired = Nrm_Sem_Rep/SemErrors_Norm * 100, Nois_Per_Sem_Error_Repaired = Nois_Sem_Rep/SemErrors_Noise *100, Nrm_Perc_Total_Error_Rep = Norm_ErrorsRepaired/TotalErrorsNorm_N *100, Nois_Per_Total_Error_Rep = Noise_ErrorsRepaired/TotalErrorsNois_N *100)%>%
replace(is.na(.), 0)%>%
group_by(Group) %>% 
summarize(Mean_Nrm_Perc_Sem_Error_Repaired = mean(Nrm_Perc_Sem_Error_Repaired),Mean_Nois_Per_Sem_Error_Repaired = mean(Nois_Per_Sem_Error_Repaired), Mean_Nrm_Perc_Total_Error_Repaired = mean(Nrm_Perc_Total_Error_Rep),Mean_Nois_Perc_Total_Error_Repaired = mean(Nois_Per_Total_Error_Rep))%>%
rename(Sem_Normal=Mean_Nrm_Perc_Sem_Error_Repaired, Sem_Noise=Mean_Nois_Per_Sem_Error_Repaired, Tot_Normal=Mean_Nrm_Perc_Total_Error_Repaired, Tot_Noise=Mean_Nois_Perc_Total_Error_Repaired)
Fig_table
skimr::skim(Fig_table)
```

```{r}
Fig1 <- Fig_table  %>%
  filter(Group==0)%>%
  gather (key = "Error", value = "Mean_Percentage_Repaired","Sem_Normal","Sem_Noise","Tot_Normal","Tot_Noise" )%>%
  ggplot() +
  geom_col(mapping = aes(x = Error,y=Mean_Percentage_Repaired), binwidth = 0.5)
 
Fig1
```


```{r}
Fig2 <- Fig_table  %>%
  gather (key = "Error", value = "Mean_Percentage_Repaired","Sem_Normal","Sem_Noise","Tot_Normal","Tot_Noise" )%>%
  ggplot() +
  geom_col(mapping = aes(x = Error,y=Mean_Percentage_Repaired), binwidth = 0.5)+
  facet_wrap(~Group)
Fig2
```


<span><font color="ff1493">
# Table 10: Regression analysis of Parkinson's disease measures

There was a descrepency for the independant variables. 4 were given: Cognitive performance, speech production, external speech perception, internal speech perception. The raw data comprises the first two independent variables was relativly clear except for the COWAT, which was distributed amongst multiple raw values. For the perception task there was no reference to rhyming in the raw data and it was not made clear in the text of the paper what that variable was. Through trial and error we were able to replicate the first two columns.

```{r}
(normModel <- lm(Norm_ErrorsRepaired ~ MMSE + RAVEN + BNT, data = allDataPatientStudyDS))
(noiseModel <- lm(Noise_ErrorsRepaired ~ MMSE + RAVEN + BNT, data = allDataPatientStudyDS))
get_regression_table(normModel)
get_regression_table(noiseModel)

```


<span><font color="ff1493">
# Table 11: Regression analysis of Parkinson's disease measures

Simple linear regressions were run for task performances as explained by Parkinson's disease measures. Duration of PD, Medication and H_Y score were used as disease measures. 

Since there are a few NA vales for H_Y variales, we used only the complete case of H_Y for our analysis. Table 11 reports just the significant findings. Based on analysis we found that only BNT was significantly explained by H_Y (p-value = 0.003), however the authors found a number of task performances significant (p-value = 0.05). Our intercept, mean squared, r squared and p-values are different from all the values that the authors have reported. Another thing we found strange was that the authors have reported p-values for the r-squared number and not for the slope coefficents (estimates). The explanatory power is given by the r-squared value and the p-value does nothing to add to that information. R-squared is used to estimate have good the model is. In other words it explains the fraction of the total variation in response variable that is explained by explanatory variables. In order to determine if the relationship between the response and explanatory variables is significant we need to look at the p-values associated with the estimates (slope-coefficents).

<span>

```{r}
Regression_table <- tidied_dataset %>%
  filter(Group == "PD",complete.cases(H_Y) )
```

```{r}
Model_sem_fluency <- lm(Semantic_Fluency~H_Y,Regression_table)
get_regression_table(Model_sem_fluency)
broom::glance(Model_sem_fluency)
```

```{r}
Model_BNT <- lm(BNT~H_Y,Regression_table)
get_regression_table(Model_BNT)
broom::glance(Model_BNT)
```
```{r}
Model_ProductionSpeedNormal <- lm(SyllSec_Norm~H_Y,Regression_table)
get_regression_table(Model_ProductionSpeedNormal)
broom::glance(Model_ProductionSpeedNormal)
```
```{r}
Model_ProductionSpeedNoise <- lm(SyllSec_Ruis~H_Y,Regression_table)
get_regression_table(Model_ProductionSpeedNoise)
broom::glance(Model_ProductionSpeedNoise)
```
```{r}
Model_DurationNorm <- 
lm(NPro_Dur_Norm~H_Y,Regression_table)
get_regression_table(Model_DurationNorm)
broom::glance(Model_DurationNorm)
```
```{r}
Model_DurationNoise <- 
lm(NPro_Dur_Ruis~H_Y,Regression_table)
get_regression_table(Model_DurationNoise)
broom::glance(Model_DurationNoise)
```
```{r}
Model_PectSemErr_Rep <- 
lm(PctSemNormRep~H_Y,allDataPatientStudyDS)
get_regression_table(Model_PectSemErr_Rep)
broom::glance(Model_PectSemErr_Rep)
```
```{r}
Model_Ntw_Perc_Sem_NErrors <- 
lm(Ntw_Perc_Sem_NErrors~H_Y,allDataPatientStudyDS)
get_regression_table(Model_Ntw_Perc_Sem_NErrors)
broom::glance(Model_Ntw_Perc_Sem_NErrors)
```

# t test for difference in the means of speech variables between Parkinson and control groups

Inspite of non-normal distribution that we saw for many variables the authors used paired t-tests to look for a difference in means between the two groups. We went ahead and checked all the assumptions for t-tests, which includes random sampling, normal distribution, large sample sizes (> 30) and homogeneity of variance (homoscedasticity). We generated qq-plots to check for assumption of normality and generated fitted vs. residual plots to check for assumption of homoscedasticity. We meet the assumptions for normality and homoscedasticity were correct. However its worth noting that the sampling was not random for the study. Most of the control subjects were partners of the parkinson patients and the parkinson patients were also not randomly selected. The n for the study is also small, with just 18 parkinson patients and 16 control patients. 
Overall there was no difference in the mean of speech production variables between the control and the pd group.


```{r Checking for distribution of BNT by group}
tidied_dataset%>%
  ggplot(aes(x=BNT)) +
  geom_histogram()+
  facet_wrap(~Group)
```

```{r}
t.test(BNT ~ Group, data = tidied_dataset, null = 0, 
       alternative = "two.sided",var.equal = TRUE)
```
```{r}
t.test(Phonologic_Fluency ~ Group, data = tidied_dataset, null = 0, 
       alternative = "two.sided",var.equal = TRUE)
```

```{r}
t.test(Semantic_Fluency ~ Group, data = tidied_dataset, null = 0, 
       alternative = "two.sided",var.equal = TRUE)
```

```{r Checking for assumptions of normality for BNT}
library("car")
qqPlot(BNT~Group,tidied_dataset)
```

```{r Checking for assumptions of normality for Phonologic Fluency}
library("car")
qqPlot(Phonologic_Fluency~Group,tidied_dataset)
```

```{r Checking for assumptions of normality for Sematic Fluency}
library("car")
qqPlot(Semantic_Fluency~Group,tidied_dataset)
```

```{r}
lmMod_Semantic <- lm(Semantic_Fluency ~ Group, data=tidied_dataset)
lmMod_Semantic_aug <- broom::augment(lmMod_Semantic)%>%
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point()
lmMod_Semantic_aug
```

```{r}
lmMod_BNT <- lm(BNT ~ Group, data=tidied_dataset)
lmMod_BNT_aug <- broom::augment(lmMod_BNT)%>%
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point()
lmMod_BNT_aug
```

```{r}
lmMod_Phonologic_Fluency <- lm(Phonologic_Fluency ~ Group, data=tidied_dataset)
lmMod_Phonologic_Fluency_aug <- broom::augment(lmMod_Phonologic_Fluency)%>%
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point()
lmMod_Phonologic_Fluency_aug
```

```{r Load error_type file}
Error_type <- read_csv("Error_type.csv")
```

```{r}
Error_type <- Error_type%>%
  mutate(Group = factor(Group), Noise = factor(Noise))
```


<span><font color="ff1493">
# ANOVA Results for Disfluencies

For total disfluencies we found no significant results for main and interaction effects of group and noise.The adjusted mean plot for the interaction model shows that mean adjusted value of total disfluencies is higher for the Parkinson group than the control under noise masking. 

For reformulation, we do see a significant group effect. The interaction plots for noise and group show that the Parkinson group has much higher mean reformulation error than the control group under noise masking. The average reformulation error increases 2.198 units for the Parkinson group. This result agrees with the results in the paper.

The adjusted mean value of filled pauses is much higher in the control group, compared to the Parkinson group,under normal conditions. However, under noise masking the adjusted mean  values of filled pauses decreases for the conytrol group, while it increases for the Parkinson group. Both, interaction and main effects are non-significant for filled pause.

For Repetition, we found no significant results for main and interaction effects of group and noise.The adjusted mean plot for the interaction model shows that mean adjusted value of Repetition errors is higher for the Parkinson group than the control under noise masking. 

Our results here somewhat agrees with the paper. It seems that control group has higher average filled pause error than the parkinson group under normal condition. While the Parkinson group has higher average reformulation and repetion errors than the control group under normal condition. 
</span>


```{r}
model_Disfluencies <- lm(Disfluencies ~ Group + Noise, data=Error_type)
anova (model_Disfluencies)
moderndive::get_regression_table(lm(Disfluencies ~ Group + Noise, data=Error_type))

```
```{r}
plot(interactionMeans(model_Disfluencies))
```

```{r}
model_Disfluencies_interact <- lm(Disfluencies ~ Group * Noise, data=Error_type, 
        contrasts = list(Group = contr.sum, 
                         Noise = contr.sum))
Anova(model_Disfluencies_interact, type = 2)
```

```{r}
plot(interactionMeans(model_Disfluencies_interact))
```

```{r}
model_Reformulation <- lm(Reformulation ~ Group + Noise, data=Error_type)
anova (model_Reformulation)
moderndive::get_regression_table(lm(Reformulation ~ Group + Noise, data=Error_type))
```

```{r}
plot(interactionMeans(model_Reformulation))
```

```{r}
model_Reformulation_interact <- lm(Reformulation ~ Group * Noise, data=Error_type, 
        contrasts = list(Group = contr.sum, 
                         Noise = contr.sum))
Anova(model_Reformulation_interact, type = 2)
```

```{r}
plot(interactionMeans(model_Reformulation_interact))
```

```{r}
model_Filled_Pause <- lm(Filled_Pause ~ Group + Noise, data=Error_type)
anova (model_Filled_Pause)
moderndive::get_regression_table(lm(Reformulation ~ Group + Noise, data=Error_type))
```
```{r}
plot(interactionMeans(model_Filled_Pause))
```

```{r}
model_Filled_Pause_interact <- lm(Filled_Pause ~ Group * Noise, data=Error_type, 
        contrasts = list(Group = contr.sum, 
                         Noise = contr.sum))
Anova(model_Filled_Pause_interact, type = 2)
```
```{r}
plot(interactionMeans(model_Filled_Pause_interact))
```

```{r}
model_Repetition <- lm(Repetition ~ Group + Noise, data=Error_type)
anova (model_Repetition)
moderndive::get_regression_table(lm(Repetition ~ Group + Noise, data=Error_type))
```
```{r}
plot(interactionMeans(model_Repetition))
```


```{r}
model_Repetition_interact <- lm(Repetition ~ Group * Noise, data=Error_type, 
        contrasts = list(Group = contr.sum, 
                         Noise = contr.sum))
Anova(model_Repetition_interact, type = 2)
```
```{r}
plot(interactionMeans(model_Repetition_interact))
```




















